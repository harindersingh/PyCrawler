Setup - done

Read seed url from console - done
Read depth from console - done
Read urls from the webpage and put them in a queue and crawl them next
Create a dictionary/map so that you don't visit a page twice - done
Exclude images from result
Write working code

Check for infinite loops, error handling

Write unit tests

Setup logging and documentation modules - doing

Handle 401, 403 kind of situations - done

Store urls in csv